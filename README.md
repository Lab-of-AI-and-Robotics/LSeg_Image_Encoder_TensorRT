# LSeg Image Encoder â€“ ONNXÂ & TensorRT

# *ì•„ì§ ì‘ì—…ì¤‘ì…ë‹ˆë‹¤! ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!!!*

> âœ¨ **Endâ€‘toâ€‘end pipeline for converting the **LSeg** image encoder to ONNX / TensorRT, benchmarking      PyTorch â†”Â TRT speed, and verifying numerical fidelity.**

ì´ í”„ë¡œì íŠ¸ëŠ” ë‘ ê°€ì§€ **LSeg image encoder** ë°±ë³¸ì„ ì§€ì›í•˜ë©°, ì‹¤í—˜ì„ í†µí•´ ì„œë¡œ ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **ViT-L/16 (non-ZS)**  
  - ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸: `conversion/model_to_onnx.py`
  - ONNX íŒŒì¼ëª… ì˜ˆì‹œ: `lseg_img_enc_vit_demo_e200.onnx`
- **ResNet101 (ZS-Variant)**  
  - ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸: `conversion/model_to_onnx_zs.py`
  - ONNX íŒŒì¼ëª… ì˜ˆì‹œ: `lseg_img_enc_rn101_fss_rn101.onnx`

ì´í›„ TRT ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ (`conversion/onnx_to_trt.py`)ë¥¼ ì´ìš©í•˜ì—¬ TensorRT Engineì„ ìƒì„±í•˜ê³ , ì´ì— ëŒ€í•œ ë¹„êµì‹¤í—˜ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 0. TL;DR Â (run everything)

```bash
# (1) install python deps
pip install -r requirements.txt  # CUDA / OpenCV must already be available

# (2) build both C++ projects in one shot
make             # or   make -j12

# (3) optional â€“ run the latency benchmark
python3 inferenceTimeTester.py  \
  --weights models/weights/demo_e200.ckpt \
  --img_sizes 260 390 520 650 780 910

# (4) run the full featureâ€‘comparison pipeline
bash python_trt_comp/run_feature_comparison.sh


```

* `make clean`  â†’Â removes **all** `CPP_Project/**/build` directories + temporary CMake artefacts.
* The **rootâ€‘level `Makefile`** is just a thin wrapper that `cmake --build`â€™s each subâ€‘directory â€“ it does **not** introduce any extra dependencies.

---

## 1. Installation
0. **System Package**
```bash
sudo apt update && sudo apt install -y \
    python3-pip python3-dev \
    libopencv-dev \
    libprotobuf-dev protobuf-compiler \
    libtinfo5 \
    libopenmpi-dev \
    cuda-toolkit-##  # CUDA Version : At least Minimum Requirement for TensorRT 10.9
```
1.  **Python**Â â‰¥3.8Â Â Â `pip install -r requirements.txt`
2.  **CUDA + TensorRTÂ 10.9**Â already installed (the repo never calls the TRT builder directly â€“ it simply links against the headers/lib).
3.  Optional but recommended:  `opencv-dev` for the C++ extractor.

---

## 2. Building  

### 2â€‘a. Oneâ€‘shot build (recommended)

```bash
# from project root
make -j$(nproc)        # builds â€¦
                      #   â€¢ CPP_Project/Inference_Time_Tester
                      #   â€¢ CPP_Project/Feature_Extractor
```
The helper `Makefile` simply iterates through everyÂ `CPP_Project/*/CMakeLists.txt`, wipes the old `build/` directory, configures withÂ `cmakeÂ -SÂ .Â -BÂ build`, then invokes the native generator.

### 2â€‘b. Perâ€‘project build (legacy)

```bash
cd CPP_Project/Inference_Time_Tester && cmake -B build -S . && cmake --build build -j
cd CPP_Project/Feature_Extractor     && cmake -B build -S . && cmake --build build -j
```

---

## 3. Project Structure

```
LSeg_Image_Encoder_TensorRT/
â”‚
â”œâ”€â”€ CPP_Project/                      # C++ í”„ë¡œê·¸ë¨ ëª¨ìŒ
â”‚   â”œâ”€â”€ Feature_Extractor/            # Feature ì¶”ì¶œê¸° í”„ë¡œì íŠ¸
â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt            # CMake ì„¤ì •
â”‚   â”‚   â””â”€â”€ main.cpp                  # Feature ì¶”ì¶œê¸° ë©”ì¸ ì½”ë“œ
â”‚   â”œâ”€â”€ Inference_Time_Tester/        # Inference ë²¤ì¹˜ë§ˆí¬ í”„ë¡œì íŠ¸
â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt            # CMake ì„¤ì •
â”‚   â”‚   â””â”€â”€ main.cpp                  # ë²¤ì¹˜ë§ˆí¬ ë©”ì¸ ì½”ë“œ
â”‚   â””â”€â”€ third_party/                  # C++ ì„œë“œ íŒŒí‹°
â”‚       â””â”€â”€ cnpy/                     # CNpy submodule for numpy I/O
â”‚
â”œâ”€â”€ Visual_Demo/                      # ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸ ë° ê²°ê³¼
â”‚   â”œâ”€â”€ demo.sh                       # demo.sh ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ demo.py                       # demo.py í˜¸ì¶œ ë˜í¼
â”‚   â”œâ”€â”€ demo_wordFree.sh              # demo_wordFree.sh ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ demo_wordFree.py              # demo_wordFree.py í˜¸ì¶œ ë˜í¼
â”‚   â””â”€â”€ images/                       # ì‹œê°í™” ê²°ê³¼ ë° ì…ë ¥ ì´ë¯¸ì§€
â”‚       â”œâ”€â”€ Dog_grass_demo.png        # segmentation ê²°ê³¼ ì˜ˆì‹œ
â”‚       â”œâ”€â”€ Dog_grass_wordFree.png    # word-free ê²°ê³¼ ì˜ˆì‹œ
â”‚       â””â”€â”€ dog_grass.jpeg            # ì…ë ¥ ì´ë¯¸ì§€ ì˜ˆì‹œ
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â”œâ”€â”€ ViT/
â”‚   â”‚   â”‚   â”œâ”€â”€ demo_e200.ckpt # ViT-L/16 CLIP checkpoint
â”‚   â”‚   â”‚   â””â”€â”€ fss_l16.ckpt # FSS-trained ViT model
â”‚   â”‚   â””â”€â”€ Resnet/
â”‚   â”‚   â”œâ”€â”€ coco_fold1.ckpt # ResNet-ZS custom
â”‚   â”‚   â”œâ”€â”€ fss_rn101.ckpt # ResNet-ZS FSS variant
â”‚   â”‚   â””â”€â”€ pascal_fold1.ckpt # ResNet-ZS custom
â”‚   â”œâ”€â”€ onnx_engines/
â”‚   â”‚   â”œâ”€â”€ lseg_img_enc_vit_demo_e200.onnx
â”‚   â”‚   â”œâ”€â”€ lseg_img_enc_vit_fss_l16.onnx
â”‚   â”‚   â”œâ”€â”€ lseg_img_enc_rn101_coco_fold1.onnx
â”‚   â”‚   â”œâ”€â”€ lseg_img_enc_rn101_fss_rn101.onnx
â”‚   â”‚   â””â”€â”€ lseg_img_enc_rn101_pascal_fold1.onnx
â”‚   â””â”€â”€ trt_engines/
â”‚   â””â”€â”€ <...>.trt # auto-generated TensorRT engines
â”‚
â”œâ”€â”€ modules/               # LSeg ëª¨ë¸ ê´€ë ¨ ì†ŒìŠ¤
â”‚   â”œâ”€â”€ lseg_module.py     # LSegModule: ì´ë¯¸ì§€ ì¸ì½”ë” + í—¤ë“œ ë˜í•‘
â”‚   â”œâ”€â”€ lseg_full.py       # LSegFull: ë°±ë³¸ê³¼ í—¤ë“œ í¬í•¨ ì „ì²´ ë„¤íŠ¸ì›Œí¬
â”‚   â”œâ”€â”€ models/            # ë‚´ë¶€ ì„œë¸Œëª¨ë“ˆ
â”‚        â”œâ”€â”€ lseg_blocks.py  # RefineNet ë¸”ë¡ê³¼ skip-connection ì²˜ë¦¬
â”‚        â”œâ”€â”€ lseg_net.py     # ë„¤íŠ¸ì›Œí¬ assemble ìœ í‹¸ë¦¬í‹°
â”‚        â””â”€â”€ lseg_vit.py     # CLIP ViT ë ˆì´ì–´ ë¶„í•  ë° feature ì¶”ì¶œ
â”‚
â”œâ”€â”€ conversion/
â”‚   â”œâ”€â”€ model_to_onnx.py # ViTâ€L/16 â†’ ONNX
â”‚   â”œâ”€â”€ model_to_onnx_zs.py # ResNet101-ZS â†’ ONNX
â”‚   â””â”€â”€ onnx_to_trt.py # ONNX â†’ TensorRT (common)
â”‚
â”œâ”€â”€ CPP_Project/
â”‚   â””â”€â”€ Inference_Time_Tester/      # C++ ë²¤ì¹˜ë§ˆí¬ í”„ë¡œì íŠ¸
â”‚       â”œâ”€â”€ CMakeLists.txt          # CMake ì„¤ì •
â”‚       â”œâ”€â”€ main.cpp                # ë²¤ì¹˜ë§ˆí¬ ë©”ì¸ ì½”ë“œ
â”‚       â””â”€â”€ build/                  # ë¹Œë“œ ê²°ê³¼ë¬¼ (trt_cpp_infer_time_tester ì‹¤í–‰íŒŒì¼)
â”‚
â”œâ”€â”€ python_trt_comp/                  # Python ê¸°ë°˜ Feature ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ compare_features.py           # Feature map ë¹„êµ (Cosine/L2)
â”‚   â”œâ”€â”€ compare_inputs.py             # ì…ë ¥ tensor ë¹„êµ
â”‚   â”œâ”€â”€ model_output.py               # PyTorch Feature ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ run_feature_comparison.sh     # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ inferenceTimeTester.py # ì¶”ë¡  ë° ë²¤ì¹˜ë§ˆí¬ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ (ë£¨íŠ¸ í´ë”)
â”‚
â”œâ”€â”€ requirements.txt       # Python íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ Makefile                    # new â€“ oneâ€‘shot builder wrapper â¶
â””â”€â”€ README.md              # ë³¸ íŒŒì¼
```

---
## 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

**Weight íŒŒì¼**ì€ LSeg ê³µì‹ ì €ì¥ì†Œì—ì„œ ê°€ì ¸ì˜¤ì„¸ìš”.
LSeg ê³µì‹ ì €ì¥ì†Œ :Â **[https://github.com/isl-org/lang-seg](https://github.com/isl-org/lang-seg)**

```bash
# ë©”ì¸ ViT-L/16 ëª¨ë¸ (demo_e200.ckpt)
pip install gdown
# demo_e200.ckpt ë‹¤ìš´ë¡œë“œ
gdown 'https://drive.google.com/uc?id=1FTuHY1xPUkM-5gaDtMfgCl3D0gR89WV7'

# FSS ë°ì´í„°ì…‹ ê¸°ë°˜ ëª¨ë¸ ì˜ˆì‹œ
# fss_rn101.ckpt (ResNet101)
gdown 'https://drive.google.com/uc?id=1UIj49Wp1mAopPub5M6O4WW-Z79VB1bhw'
# fss_l16.ckpt (ViT-L/16)
gdown 'https://drive.google.com/uc?id=1Nplkc_JsHIS55d--K2vonOOC3HrppzYy'
```

ë‹¤ìš´ë¡œë“œí•œ ì²´í¬í¬ì¸íŠ¸ëŠ” `models/weights/` ì•„ë˜ì— ì €ì¥í•˜ì„¸ìš”.

---
## 5. Building ONNX & TensorRT Engines

### 5-a. ONNX ëª¨ë¸ ë³€í™˜

- **ViT ë°±ë³¸**  
  ```bash
    python3 conversion/model_to_onnx.py \
      --weights models/weights/ViT/demo_e200.ckpt
  ```
  * `--weights`: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ

  â†’ `models/onnx_engines/lseg_img_enc_vit_demo_e200.onnx`

- **ResNet-ZS ë°±ë³¸**
    
    ```bash
      python3 conversion/model_to_onnx_zs.py \
        --weights models/weights/Resnet/fss_rn101.ckpt
    ```
    * `--weights`: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ

    â†’ `models/onnx_engines/lseg_img_enc_rn101_fss_rn101.onnx`
    

### 5-b. TensorRT ì—”ì§„ ë³€í™˜
**ì£¼ì˜**: TensorRT ë³€í™˜ì€ GPU ë° í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥´ë¯€ë¡œ, **ì‹¤í–‰í•  ê¸°ê¸°ì—ì„œ ì§ì ‘ ë³€í™˜**í•´ì•¼ í•©ë‹ˆë‹¤.
```bash
python3 conversion/onnx_to_trt.py \
  --onnx models/onnx_engines/<base>.onnx \
  --workspace 1073741824 \
  --fp16 \
  --sparse \
  --disable-timing-cache \
  --gpu-fallback \
  --debug
```

-   ViT, ResNet-ZS ëª¨ë‘ ê³µí†µìœ¼ë¡œ `onnx_to_trt.py`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
-   ìƒì„±ëœ ì—”ì§„ì€ `models/trt_engines/` ì— ì €ì¥ë©ë‹ˆë‹¤.


  #### TensorRT ì˜µì…˜ ì„¤ëª…

  | ì˜µì…˜                         | ì¢…ë¥˜      | ê¸°ë³¸ê°’     | ì„¤ëª…                           |
  | -------------------------- | ------- | ------- | ---------------------------- |
  | `--onnx <PATH>`            | í•„ìˆ˜    | â€”      | ì…ë ¥ ONNX íŒŒì¼ ê²½ë¡œ                |
  | `--workspace <BYTE>`       | integer | `1<<29` | ë¹Œë” ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë©”ëª¨ë¦¬(ë°”ì´íŠ¸)           |
  | `--fp16` / `--no-fp16`     | flag    |  true   | FP16 ì—°ì‚° ì‚¬ìš© ì—¬ë¶€                |
  | `--sparse` / `--no-sparse` | flag    |  true   | Sparse weights ì „ìˆ  ì‚¬ìš© ì—¬ë¶€      |
  | `--disable-timing-cache`   | flag    | false   | íƒ€ì´ë° ìºì‹œ ë¹„í™œì„±í™” (ë¹Œë“œ ì•ˆì •ì„± â†‘, ì†ë„ â†“) |
  | `--gpu-fallback`           | flag    | false   | INT8 ëª¨ë“œì—ì„œ GPU ì—°ì‚° í´ë°± í—ˆìš©       |
  | `--debug`                  | flag    | false   | ë””ë²„ê·¸ ë¡œê·¸ í™œì„±í™”                   |

  **ì—”ì§„ íŒŒì¼ëª… ìë™ ìƒì„± ê·œì¹™**: `base__<ì˜µì…˜1>_<ì˜µì…˜2>_..._<wsXXMiB>.trt`

---

## 6.  Latency Benchmark

`inference/inferenceTimeTester.py` ë¥¼ ì‹¤í–‰í•˜ì—¬ **PyTorch, ONNX, TensorRT** ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

```bash
python3 inferenceTimeTester.py \
  --weights_dir models/weights \
  --img_sizes 256 320 384 480 640 768 1024 \
  --iterations 1000 \
  --trt_fp16 --trt_sparse --trt_no_tc --trt_gpu_fb --trt_debug \
  --trt_workspace 1073741824
```
-   `--weights_dir models/weights`
    
    -   `ViT/` ì•ˆì˜ `.ckpt` â†’ ViT non-ZS ëª¨ë¸
        
    -   `Resnet/` ì•ˆì˜ `.ckpt` â†’ ResNet-ZS ëª¨ë¸
* `--img_sizes`: í…ŒìŠ¤íŠ¸í•  ì…ë ¥ í¬ê¸° ëª©ë¡
* `--iterations`: ë°˜ë³µ íšŸìˆ˜
* `--trt_*`: TRT ë¹Œë“œ ì˜µì…˜ (ONNXâ†’TRTì— ìë™ ë°˜ì˜)



**ìŠ¤í¬ë¦½íŠ¸ ë™ì‘**:

1. ONNX íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
2. TRT ì—”ì§„ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
3. PyTorch â†’ ONNX â†’ TRT ìˆœìœ¼ë¡œ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬

**ê²°ê³¼ ì˜ˆì‹œ**:
-   ê²°ê³¼ëŠ” Backbone, Checkpoint, Size ë³„ë¡œ Avg(ms) Â± Std(ms) í…Œì´ë¸”ë¡œ ìš”ì•½ë©ë‹ˆë‹¤.
    ```
    [RESULT] PyTorch Avg: 12.345 ms Â± 0.123 ms
    [RESULT] ONNX   Avg: 10.567 ms Â± 0.098 ms
    [RESULT] TRT    Avg:  5.432 ms Â± 0.045 ms
    ```

### 6â€‘a. Test rig

```
AMDÂ RyzenÂ 7Â 9700X  | 8Câ€¯/â€¯16T @ 5.0â€¯GHz
NVIDIAÂ RTXÂ 4090    | 24â€¯GB (Ada, 550â€¯W limit)
64â€¯GBÂ DDR5â€‘6000    | dualâ€‘rank
TensorRTÂ 10.9 + CUDAÂ 12.2, PyTorchÂ 2.3 (cu118)
UbuntuÂ 22.04 LTS   | LinuxÂ 6.5
```

Hardware script (`hardware_spec.sh`) dumps the table automatically.

### 6â€‘b. Results  
`inferenceTimeTester.pyÂ --iterations 1000`

#### ResNet101-ZS

| Size | PyTorch **ms** | Â± | TRT-Python **ms** | Â± | TRT-C++ **ms** | Â± |
| --- | --- | --- | --- | --- | --- | --- |
| 256 | 3.73 | 0.11 | 3.23 | 0.05 | **1.60** | 0.15 |
| 320 | 4.33 | 0.32 | 4.27 | 0.04 | **1.71** | 0.15 |
| 384 | 5.23 | 0.46 | 5.60 | 0.04 | **1.92** | 0.15 |
| 480 | 6.80 | 0.63 | 8.34 | 0.18 | **2.49** | 0.31 |
| 640 | 10.93 | 1.02 | 14.54 | 0.23 | **4.12** | 0.28 |
| 768 | 15.99 | 1.28 | 21.16 | 0.22 | **6.17** | 0.36 |
| 1024 | 27.23 | 2.32 | 37.34 | 0.32 | **10.49** | 0.34 |


#### ViT-L/16 (non-ZS)

| Size | PyTorch **ms** | Â± | TRT-Python **ms** | Â± | TRT-C++ **ms** | Â± |
| --- | --- | --- | --- | --- | --- | --- |
| 256 | 10.57 | 1.09 | 5.55 | 0.12 | **3.89** | 0.25 |
| 320 | 14.03 | 1.50 | 6.87 | 0.15 | **4.60** | 0.30 |
| 384 | 20.41 | 1.93 | 8.55 | 0.35 | **4.71** | 0.39 |
| 480 | 28.30 | 2.58 | 11.63 | 0.29 | **5.78** | 0.24 |
| 640 | 57.76 | 4.78 | 21.70 | 0.34 | **10.44** | 0.46 |
| 768 | 79.41 | 6.04 | 31.13 | 1.84 | **15.77** | 0.60 |
| 1024 | 173.31 | 12.30 | 58.65 | 1.42 | **30.85** | 0.66 |

**Observations**

[TensorRT Optimization]

* TensorRTÂ ( Python API ) already yields a **2â€¯â€“â€¯3Ã— speedâ€‘up** over eager PyTorch.
* The minimalist C++ runner shaves **another ~40â€¯% latency**, dominated by
  * avoiding `pycuda`Â /Â DLPack marshalling overheads;
  * preâ€‘parsing I/O tensor indices at startâ€‘up.
* Slope â‰ˆâ€¯O(NÂ²) w.r.t spatial resolution (expected for ViT windowed attention).

[Backbone Image Encoder]
-   **ResNet-ZS vs ViT (PyTorch eager)**
    -   ResNet-ZS is ~2.8Ã— faster at 256Â² (3.7 ms vs 10.6 ms) and the gap widens to ~6.4Ã— at 1024Â² (27.2 ms vs 173.3 ms).
-   **ResNet-ZS vs ViT (TRT-Python)**
    -   Speed-up is milder (â‰ˆ1.3â€“1.5Ã—), e.g. 3.2 ms vs 5.6 ms at 256Â², and 37.3 ms vs 58.6 ms at 1024Â².
-   **ResNet-ZS vs ViT (TRT-C++)**
    -   C++ runner further reduces latency by ~35â€“40 %; ResNet-ZS: 1.6 msâ†’ vs ViT: 3.9 ms at 256Â².
-   **Overall**
    -   ResNet-ZS offers much lower absolute latency across all APIs, while ViTâ€™s heavier computation makes its acceleration benefits more dramatic under TensorRT.

---

### 7. Demo Scripts

### Visual_Demo/demo.sh

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” **ONNX ëª¨ë¸**ì„ ì´ìš©í•´ ì˜ˆì‹œ ì´ë¯¸ì§€ë¥¼ ë¶„í• (segmentation)í•˜ê³ , ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

```bash
# ì‚¬ìš© ì˜ˆì‹œ (ë£¨íŠ¸ì—ì„œ ì‹¤í–‰)
python3 Visual_Demo/demo.py --image Visual_Demo/images/dog_grass.jpeg \
                            --labels "dog, grass, other" \
                            --onnx models/onnx_engines/lseg_img_enc_vit_ade20k.onnx \
                            --size 384
```

* `--image`: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
* `--labels`: ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„ëœ ë¼ë²¨ ëª©ë¡ (ì˜ˆ: "cat, sky, building")
* `--onnx`: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
* `--size`: ëª¨ë¸ ì…ë ¥ í¬ê¸° (HxW)

ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ì—ì„œëŠ” `demo.py` ë¥¼ í˜¸ì¶œí•˜ë©°, ì¢Œì¸¡ì— ì›ë³¸ ì´ë¯¸ì§€, ìš°ì¸¡ì— segmentation ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.


### Visual_Demo/demo\_wordFree.sh

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” **Full CLIP Vocab ê¸°ë°˜** í”½ì…€ ë‹¨ìœ„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ê³ , **ë“±ì¥í•œ ë‹¨ì–´**ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•˜ë©° ì‹œê°í™”í•©ë‹ˆë‹¤.

```bash
# ì‚¬ìš© ì˜ˆì‹œ (ë£¨íŠ¸ì—ì„œ ì‹¤í–‰)
python3 Visual_Demo/demo_wordFree.py --image Visual_Demo/images/dog_grass.jpeg \
                                     --onnx models/onnx_engines/lseg_img_enc_vit_ade20k.onnx \
                                     --size 384
```

* `--image`: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
* `--onnx`: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
* `--size`: ëª¨ë¸ ì…ë ¥ í¬ê¸° (HxW)

ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ì—ì„œëŠ” `demo_wordFree.py` ë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ ë‚´ í”½ì…€ë§ˆë‹¤ CLIP ì „ì²´ vocab ì¤‘ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ í† í°ì„ ì„ íƒ, í•´ë‹¹ ë‹¨ì–´ë“¤ì„ ì¶œë ¥í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

### Visual Results

ì•„ë˜ëŠ” `Visual_demo/images/` í´ë”ì— ì €ì¥ëœ ì˜ˆì‹œ ê²°ê³¼ì…ë‹ˆë‹¤:

|                     Segmentation (`demo.py`)                     |                  Word-free (`demo_wordFree.py`)                  |      |
| :--------------------------------------------------------------: | :--------------------------------------------------------------: | ---- |
| ![Dog Grass Segmentation](Visual_Demo/images/Dog_grass_demo.png) | ![Dog Grass WordFree](Visual_Demo/images/Dog_grass_wordFree.png) |

---

## 8.  Featureâ€‘map Extraction & Comparison

| **Script / Binary** | **Role** | **Backend** |
|---------------------|-------------------------------------------|-----------|
| `python_trt_comp/model_output.py` | Loads an LSeg checkpoint, **removes the decoder**, runs the encoder only and dumps a   `(B,512,H/2,W/2)` featureâ€‘tensor to `npy`. | PyTorch |
| `CPP_Project/Feature_Extractor/build/trt_feature_extractor` | Deserialises the dynamicâ€‘shape **TensorRTÂ engine**, feeds a BGRÂ image, and writes the identical featureâ€‘tensor. | TensorRTÂ C++ |
| `python_trt_comp/compare_features.py` | Loads both tensors, flattens them, outputs **cosine similarity** & **L2Â norm**. | PyTorch (CPU) |
| `python_trt_comp/run_feature_comparison.sh` | Glue: loops over several images Ã— checkpoints Ã— resolutions. | bash |

ì „ì²´ Feature ì¶”ì¶œ ë° ë¹„êµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:

```bash
bash python_trt_comp/run_feature_comparison.sh
```

* `run_feature_comparison.sh`: `model_output.py`, C++ Feature Extractor, `compare_features.py` ìˆœì°¨ ì‹¤í–‰
* ê²°ê³¼ëŠ” `outputs/` í´ë”ì™€ ì½˜ì†” ë¡œê·¸ë¡œ í™•ì¸í•©ë‹ˆë‹¤.

---

### 8â€‘a. Numericalâ€‘fidelity results  
*(RTXÂ 4090Â +Â TensorRTÂ 10.9 â€“ FP16 engine, sparse weights)*

| **Size** | **Cosineâ€†(â†‘)Â â€“Â PyTorchÂ vsÂ TRT** | **L2â€†(â†“)** |
|-------:|---------------:|-----------:|
| 480 | **1.0007** | 1.43 |
| 384 | **1.0010** | 5.67 |
| 320 | **1.0012** | 3.91 |
| 260 | **1.0007** | 1.26 |

*Cosine â‰ˆâ€¯1.0* implies that FP16 quantisation + builder optimisations introduce **<0.1â€¯% angular error** â€“ well within acceptable limits for CLIPâ€‘style similarity retrieval.

### 8-b ğŸ“Š Crossâ€‘Tag Feature Map Comparison (ade20kÂ vsÂ fss)

| Size (px) | Framework | Cosineâ€¯Similarity | L2â€¯Distance |
|-----------|-----------|------------------:|------------:|
| **480** | PyTorch | **â€‘0.025655** | **343.642** |
|           | TensorRTÂ C++ | â€‘0.026256 | 343.743 |
| **384** | PyTorch | **â€‘0.013745** | **273.327** |
|           | TensorRTÂ C++ | â€‘0.014547 | 273.434 |
| **320** | PyTorch | **â€‘0.004119** | **226.718** |
|           | TensorRTÂ C++ | â€‘0.004628 | 226.775 |
| **260** | PyTorch | **â€‘0.003275** | **181.305** |
|           | TensorRTÂ C++ | â€‘0.003252 | 181.303 |

> *Negative cosine similarity indicates that the aggregated visual embeddings for **ade20k** and **fss** tags are nearly orthogonal, reflecting the distinct semantic domains of the two training sets.  
> The L2 distances corroborate this, staying consistently in the 180â€’340 range across spatial scales.  
> TensorRT outputs track PyTorch extremely closely (<â€¯0.001 absolute delta in cosine; <â€¯0.1â€¯% in L2), confirming numerical parity after quantisation and kernel fusion.*

### 8-c Visual Results

ì•„ë˜ëŠ” `Visual_demo/images/` í´ë”ì— ì €ì¥ëœ ì˜ˆì‹œ ê²°ê³¼ì…ë‹ˆë‹¤:
![PT TRT Comparison](Visual_Demo/images/pt_trt_comp_cat1.png)

---

## 9. Additional Notes

* **ONNX opset\_version=14** ì‚¬ìš©
* ë™ì  ì…ë ¥ í¬ê¸° ì§€ì›: `torch.onnx.export(... dynamic_axes=...)` ì„¤ì • ì°¸ì¡°
* GPU ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•´ `onnxruntime-gpu` í•„ìš”: `pip install onnxruntime-gpu`
* CUDAExecutionProvider í™•ì¸:

```python
import onnxruntime as ort
print(ort.get_available_providers())
```

---

## 10. License

MIT â€“ see `LICENSE` for details.

---

## 11. Acknowledgements

Portions of the code are adapted from **ISLâ€‘org / langâ€‘seg** (Apacheâ€‘2.0) and **NVIDIA TensorRTÂ samples**.
